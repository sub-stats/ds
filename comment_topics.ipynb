{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim import corpora\n",
    "import re\n",
    "import string\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (0,2,5,14,16,17,18,19,21,24,26,27,32,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/sub-stats/ds/master/4-30-to-7-29-comments.csv')\n",
    "df.loc[df['body'].isnull(), 'body'] = 'Null'\n",
    "df['retrieved_on'] = pd.to_datetime(df['retrieved_on'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157453, 37)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>all_awardings</th>\n",
       "      <th>approved_at_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>author_cakeday</th>\n",
       "      <th>author_flair_background_color</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_richtext</th>\n",
       "      <th>author_flair_template_id</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>...</th>\n",
       "      <th>no_follow</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>permalink</th>\n",
       "      <th>retrieved_on</th>\n",
       "      <th>score</th>\n",
       "      <th>send_replies</th>\n",
       "      <th>stickied</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>total_awards_received</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HEROROYDEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>t1_evdwqpw</td>\n",
       "      <td>/r/AskReddit/comments/cjjtnn/people_of_reddit_...</td>\n",
       "      <td>2019-07-30 01:28:02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>t5_2qh1i</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>marlashannon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>t1_evdvpyz</td>\n",
       "      <td>/r/AskReddit/comments/cjjtnn/people_of_reddit_...</td>\n",
       "      <td>2019-07-30 01:17:41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>t5_2qh1i</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HEROROYDEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>t1_evdsoc2</td>\n",
       "      <td>/r/AskReddit/comments/cjjtnn/people_of_reddit_...</td>\n",
       "      <td>2019-07-30 01:05:12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>t5_2qh1i</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ahlannister</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>t3_cjjtnn</td>\n",
       "      <td>/r/AskReddit/comments/cjjtnn/people_of_reddit_...</td>\n",
       "      <td>2019-07-30 01:04:39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>t5_2qh1i</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dobbeo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>t3_cjjtnn</td>\n",
       "      <td>/r/AskReddit/comments/cjjtnn/people_of_reddit_...</td>\n",
       "      <td>2019-07-30 00:47:52</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>t5_2qh1i</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0 all_awardings approved_at_utc        author author_cakeday  \\\n",
       "0          0            []             NaN    HEROROYDEN            NaN   \n",
       "1          1            []             NaN  marlashannon            NaN   \n",
       "2          2            []             NaN    HEROROYDEN            NaN   \n",
       "3          3            []             NaN   ahlannister            NaN   \n",
       "4          4            []             NaN        Dobbeo            NaN   \n",
       "\n",
       "  author_flair_background_color author_flair_css_class author_flair_richtext  \\\n",
       "0                           NaN                    NaN                    []   \n",
       "1                           NaN                    NaN                    []   \n",
       "2                           NaN                    NaN                    []   \n",
       "3                           NaN                    NaN                    []   \n",
       "4                           NaN                    NaN                    []   \n",
       "\n",
       "  author_flair_template_id author_flair_text  ... no_follow   parent_id  \\\n",
       "0                      NaN               NaN  ...      True  t1_evdwqpw   \n",
       "1                      NaN               NaN  ...      True  t1_evdvpyz   \n",
       "2                      NaN               NaN  ...      True  t1_evdsoc2   \n",
       "3                      NaN               NaN  ...      True   t3_cjjtnn   \n",
       "4                      NaN               NaN  ...      True   t3_cjjtnn   \n",
       "\n",
       "                                           permalink        retrieved_on  \\\n",
       "0  /r/AskReddit/comments/cjjtnn/people_of_reddit_... 2019-07-30 01:28:02   \n",
       "1  /r/AskReddit/comments/cjjtnn/people_of_reddit_... 2019-07-30 01:17:41   \n",
       "2  /r/AskReddit/comments/cjjtnn/people_of_reddit_... 2019-07-30 01:05:12   \n",
       "3  /r/AskReddit/comments/cjjtnn/people_of_reddit_... 2019-07-30 01:04:39   \n",
       "4  /r/AskReddit/comments/cjjtnn/people_of_reddit_... 2019-07-30 00:47:52   \n",
       "\n",
       "  score send_replies stickied  subreddit subreddit_id total_awards_received  \n",
       "0   1.0         True    False  AskReddit     t5_2qh1i                   0.0  \n",
       "1   1.0         True    False  AskReddit     t5_2qh1i                   0.0  \n",
       "2   1.0         True    False  AskReddit     t5_2qh1i                   0.0  \n",
       "3   1.0         True    False  AskReddit     t5_2qh1i                   0.0  \n",
       "4   1.0         True    False  AskReddit     t5_2qh1i                   0.0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'all_awardings', 'approved_at_utc', 'author',\n",
       "       'author_cakeday', 'author_flair_background_color',\n",
       "       'author_flair_css_class', 'author_flair_richtext',\n",
       "       'author_flair_template_id', 'author_flair_text',\n",
       "       'author_flair_text_color', 'author_flair_type', 'author_fullname',\n",
       "       'author_patreon_flair', 'banned_at_utc', 'body', 'can_mod_post',\n",
       "       'collapsed', 'collapsed_reason', 'created_utc', 'distinguished',\n",
       "       'edited', 'gildings', 'id', 'is_submitter', 'link_id', 'locked',\n",
       "       'no_follow', 'parent_id', 'permalink', 'retrieved_on', 'score',\n",
       "       'send_replies', 'stickied', 'subreddit', 'subreddit_id',\n",
       "       'total_awards_received'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[['body', 'subreddit', 'retrieved_on']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = spacy.lang.en.STOP_WORDS\n",
    "stopwords |= {'\\n\\n\\n', '\\n\\n', '\\n', 'amp;#x200B', 'reddit', '/r', '/r/', 'r/', '%', '_',\n",
    "              'like', 'that', 'this', 'r', 'askhistorians', 'if', 'the', 'thing', 'things',\n",
    "              'question', 'questions', 'answer', 'answers', 'gt', '\\&gt', 'wiki', 'subreddit',\n",
    "              'askphilosophy', 'philosophy', 'op', 'comment', 'comments', 'account', 'repost',\n",
    "              'notification', 'notifications', 'message', 'messages', 'lot', 'engineer', \n",
    "              'engineering', 'askscience', 'flair', 'moderator', 'mod', 'mods', 'askreddit',\n",
    "              'askcomputerscience', 'askculinary', 'trueaskreddit', 'asksocialscience', \n",
    "              'askengineers', 'nan', 'search?q', 'thanks', 'ban', 'way'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "tokens = []\n",
    "punctuations = string.punctuation\n",
    "stopwords = spacy.lang.en.STOP_WORDS\n",
    "\n",
    "def word_is_good(word):\n",
    "    return ((word.text not in stopwords) and \n",
    "            (word.pos_ == 'NOUN') and\n",
    "            (word.pos_ != 'PUNCT') and\n",
    "            (word.pos_ != 'SYM') and\n",
    "            (word.lemma_ != '-PRON-'))\n",
    "    \n",
    "for doc in nlp.pipe(df2['body'].astype('unicode').values, batch_size=50,\n",
    "                        n_threads=4):\n",
    "    if doc.is_parsed:\n",
    "        tokens.append([n.text.lower() for n in doc if word_is_good(n)])\n",
    "\n",
    "df2['comment_tokens'] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>retrieved_on</th>\n",
       "      <th>comment_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How is he a buffoon then you idiot.</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>2019-07-30 01:28:02</td>\n",
       "      <td>[buffoon, idiot]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I didn’t say racist. I said buffoon. Completel...</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>2019-07-30 01:17:41</td>\n",
       "      <td>[buffoon]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LMAO you are hilarious. How can I be this stup...</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>2019-07-30 01:05:12</td>\n",
       "      <td>[remarks, rat, city, people, raciests]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eat rice, beans and salad together at lunch</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>2019-07-30 01:04:39</td>\n",
       "      <td>[rice, beans, salad, lunch]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Consuming copious amount of cheese.</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>2019-07-30 00:47:52</td>\n",
       "      <td>[cheese]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  subreddit  \\\n",
       "0                How is he a buffoon then you idiot.  AskReddit   \n",
       "1  I didn’t say racist. I said buffoon. Completel...  AskReddit   \n",
       "2  LMAO you are hilarious. How can I be this stup...  AskReddit   \n",
       "3        Eat rice, beans and salad together at lunch  AskReddit   \n",
       "4                Consuming copious amount of cheese.  AskReddit   \n",
       "\n",
       "         retrieved_on                          comment_tokens  \n",
       "0 2019-07-30 01:28:02                        [buffoon, idiot]  \n",
       "1 2019-07-30 01:17:41                               [buffoon]  \n",
       "2 2019-07-30 01:05:12  [remarks, rat, city, people, raciests]  \n",
       "3 2019-07-30 01:04:39             [rice, beans, salad, lunch]  \n",
       "4 2019-07-30 00:47:52                                [cheese]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "AskReddit\n",
      "------------------\n",
      "day life guy night time\n",
      "shrek man friend years shit\n",
      "people water food music fuck\n",
      "person money year job time\n",
      "time people friends life game\n",
      "\n",
      "\n",
      "AskHistorians\n",
      "------------------\n",
      "history time women people period\n",
      "war time thanks people sources\n",
      "people time century word fact\n",
      "people time war century point\n",
      "time depth on&amp;sort interest rules\n",
      "\n",
      "\n",
      "AskCulinary\n",
      "------------------\n",
      "bread recipe cooking baking recipes\n",
      "salt cream rice iron pepper\n",
      "time chicken chocolate recipe oven\n",
      "sauce meat dough flavor water\n",
      "water heat pan thanks egg\n",
      "\n",
      "\n",
      "AskEngineers\n",
      "------------------\n",
      "job work company time experience\n",
      "system power heat air pressure\n",
      "job software position day cars\n",
      "school time job people degree\n",
      "people years work job engineers\n",
      "\n",
      "\n",
      "askscience\n",
      "------------------\n",
      "language post save information games\n",
      "time cells years people life\n",
      "post forum = concerns action\n",
      "body brain species effect sugar\n",
      "water energy air temperature light\n",
      "\n",
      "\n",
      "askphilosophy\n",
      "------------------\n",
      "people p example problem conclusion\n",
      "time sense argument view self\n",
      "life time existence point experience\n",
      "answers rules rule violations op\n",
      "knowledge theory philosophers p science\n",
      "\n",
      "\n",
      "TrueAskReddit\n",
      "------------------\n",
      "fear reason child food time\n",
      "games people time today game\n",
      "people person country traits world\n",
      "people life world children problem\n",
      "quality action discussion topic moderators\n",
      "\n",
      "\n",
      "AskComputerScience\n",
      "------------------\n",
      "hash input function people functions\n",
      "code bytes memory files problems\n",
      "bit code function time number\n",
      "computer math degree programming stuff\n",
      "data time problem solution system\n",
      "\n",
      "\n",
      "AskSocialScience\n",
      "------------------\n",
      "criminology sociology differences men women\n",
      "people information society psychology person\n",
      "population groups scientists humans concept\n",
      "group countries behavior example groups\n",
      "children study time people research\n"
     ]
    }
   ],
   "source": [
    "subs = ['AskReddit', 'AskHistorians', 'AskCulinary', 'AskEngineers', 'askscience',\n",
    "        'askphilosophy', 'TrueAskReddit', 'AskComputerScience', 'AskSocialScience']\n",
    "for subreddit in subs:\n",
    "    conditions = ((df2['comment_tokens'].str.len() > 0) & (df2['subreddit'] == subreddit))\n",
    "    # A Dictionary Representation of all the words in our corpus\n",
    "    id2word = corpora.Dictionary(df2[conditions]['comment_tokens'])\n",
    "\n",
    "    # Let's remove extreme values from the dataset\n",
    "    id2word.filter_extremes(no_below=10, no_above=0.85)\n",
    "\n",
    "    corpus = [id2word.doc2bow(text) for text in df2[conditions]['comment_tokens']]\n",
    "    \n",
    "    lda = LdaMulticore(corpus=corpus,\n",
    "                   id2word=id2word,\n",
    "                   random_state=42,\n",
    "                   num_topics = 5,\n",
    "                   passes=5,\n",
    "                   workers=4)\n",
    "    \n",
    "    words = [re.findall(r'\"([^\"]*)\"', t[1]) for t in lda.print_topics()]\n",
    "    topics = [' '.join(t[0:5]) for t in words]\n",
    "\n",
    "    print('\\n\\n' + subreddit + '\\n------------------')\n",
    "    for topic in topics:\n",
    "        print(topic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
